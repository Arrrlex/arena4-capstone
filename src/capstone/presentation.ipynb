{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalising Deception:  Do 'Lying Vectors' Transfer Across Datasets?\n",
    "\n",
    "### By Tinuade Margaret, Gergely Kiss, Alex McKenzie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "What are we trying to do?\n",
    "\n",
    "- We’re interested in understanding what a model is thinking when it lies\n",
    "- Is “lying” a linear feature learned by the model? \n",
    "    - i.e. Is it represented as a single direction in activation space?\n",
    "- Is “lying” generalizable? \n",
    "    - i.e. does the same direction do the same thing in different contexts?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we care?\n",
    "- Lying capability is highly relevant to deception\n",
    "- Interventions could help make models more honest\n",
    "    - Always good to have more model steering options!\n",
    "\n",
    "<img src=\"imgs/shoggoth.webp\" width=\"500\" alt=\"Shoggoth lying\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- We used Gemma 2 9B instruction tuned\n",
    "- We fairly closely followed the [Function Vectors](https://arena3-chapter1-transformer-interp.streamlit.app/[1.4.2]_Function_Vectors_&_Model_Steering) course material, and the [“Geometry of Truth” paper by Samuel Marks & Max Tegmark](https://arxiv.org/abs/2310.06824).\n",
    "- We only investigated lying _upon prompting_, rather than due to fine-tuning, instrumental goals, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can Gemma 2 even lie?\n",
    "\n",
    "Gemma-2-9b is RLHF-ed not to lie, but it's very easy to get around that\n",
    "\n",
    "<img src=\"imgs/lie.png\" width=\"500\" alt=\"Chat logs of Gemma-2-9b lying\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can Gemma 2 lie on a multiple-choice question?\n",
    "\n",
    "Yes.\n",
    "\n",
    "![](imgs/mcq_lie.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation\n",
    "\n",
    "- We used GPT4 and Sonnet 3.5 to generate datasets:\n",
    "    - Multiple-choice questions at different levels\n",
    "        - For five-year-olds (\"\")\n",
    "        - For twelve-year-olds (\"\")\n",
    "    - True or false statements (\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation (cont.)\n",
    "\n",
    "Can Gemma 2 9B answer these questions correctly?\n",
    "\n",
    "Can it successfully lie, i.e. give the incorrect answer, when prompted to do so?\n",
    "\n",
    "Answer: yes\n",
    "\n",
    "(insert bar chart here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating Hidden State Activations\n",
    "\n",
    "- Does it make sense to try to extract directions for lying?\n",
    "- Let's see if the hidden-state activations while lying & being honest are linearly separable\n",
    "- Turns out they are\n",
    "\n",
    "(Insert PCA visualisation here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of Lying Vectors\n",
    "\n",
    "We split our \"12-year-old multiple choice question\" dataset into a train & test split (75:25).\n",
    "\n",
    "We compute a \"lying vector\" at layer $\\ell$ as follows:\n",
    "1. Let $V^{(\\ell)}_{\\textit{honest}}$ be the mean activation at layer $\\ell$ of our train split, when prompted for honesty;\n",
    "2. Let $V^{(\\ell)}_{\\textit{lie}}$ be the mean activation when prompted for dishonesty;\n",
    "3. Then our lying vector is $V^{(\\ell)}_{\\textit{lie}} - V^{(\\ell)}_{\\textit{honest}}$\n",
    "\n",
    "Why this method? \n",
    "- It's used in the Tegmark paper\n",
    "- We didn't have time to try anything else :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Methodology & Results  \n",
    "  * Investigation: which layers should we use? How strongly should we intervene?  \n",
    "    * For different “intervention coefficients” and different layers, try adding the lying vector when running the test set through the model  \n",
    "    * We look at “normalised indirect effect” i.e. how big is the difference between the wrong answer and the right answer log probs, normalised by the (absolute) difference without intervention  \n",
    "    * Heat map \\-\\> use layer 21 and coefficient ??  \n",
    "  * Result: as the coefficient increases, the chance the model outputs a lie in the wrong format increases (“can’t think about anything other than lying”)  \n",
    "    * Plot: one line “truth”, one line “lie”, one line “incorrect format” for layer 21 as coefficient varies  \n",
    "    * This is somewhat interesting finding by itself  \n",
    "    * But we are interested in lying even when the model formats its result incorrectly. Thus we delegate to a model to decide if the model has answered correctly  \n",
    "    * Plot: the same thing but with model as a judge\n",
    "  * Investigation: does this lying direction generalise to other datasets?  \n",
    "    * Dataset 1: the same format, but different (easier) questions  \n",
    "      * Result: ???  \n",
    "    * Dataset 2: the same (test) dataset, but with the prompts changed from “A. \\<answer\\> B. \\<answer\\>” to “1. \\<answer\\> 2\\. \\<answer\\>”  \n",
    "      * Result: ???  \n",
    "    * Dataset 3: true-or-false statements  \n",
    "      * Result: ???  \n",
    "* Conclusion  \n",
    "  * The lying direction somewhat generalises (??) to other datasets, but our results aren’t very robust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
